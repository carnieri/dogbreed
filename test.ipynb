{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05319ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from itertools import zip_longest\n",
    "from fastai.vision.all import *\n",
    "from utils import label_func, slice_model, get_embedding_from_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fe1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(\"dogs/train/exported_resnext50_32x4d.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = slice_model(learn.model, to_layer=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f895ada",
   "metadata": {},
   "source": [
    "## Calculate embeddings for test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795aff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_base = \"dogs/recognition/test/\"\n",
    "test_paths = get_image_files(test_path_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into non-overlapping fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate embeddings in batches, for faster inference\n",
    "embeddings = []\n",
    "bs = 64\n",
    "for batch in grouper(test_paths, bs):\n",
    "    # remove filler values (may appear in last batch)\n",
    "    batch = [x for x in batch if x is not None]\n",
    "    es = get_embedding_from_paths(learn, embedder, batch)\n",
    "    embeddings.extend(es)\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f09df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"embeddings.shape: {embeddings.shape}\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(embeddings, open(\"test_embeddings.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "for test_path, embedding in zip(test_paths, embeddings):\n",
    "    embedding_dict[test_path] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4806ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(embedding_dict, open(\"test_embedding_dict.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2dffe",
   "metadata": {},
   "source": [
    "## Enroll new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embeddings_for_dataset(learn, paths, bs=64):\n",
    "    embedder = slice_model(learn.model, to_layer=-1)\n",
    "    embeddings = []\n",
    "    for batch in grouper(paths, bs):\n",
    "        # remove filler values (may appear in last batch)\n",
    "        batch = [x for x in batch if x is not None]\n",
    "        es = get_embedding_from_paths(learn, embedder, batch)\n",
    "        embeddings.extend(es)\n",
    "    embeddings = np.array(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_paths = get_image_files(\"dogs/recognition/enroll/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_embeddings = calculate_embeddings_for_dataset(learn, enroll_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(enroll_embeddings, open(\"enroll_embeddings.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_dict(paths, embeddings):\n",
    "    return dict(zip(paths, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fcae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_embedding_dict = make_embedding_dict(enroll_paths, enroll_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6384cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(enroll_embedding_dict, open(\"enroll_embedding_dict.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa979686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef00e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342bc11f",
   "metadata": {},
   "source": [
    "## Train classifier for embeddings\n",
    "Reference: https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy = enroll_embeddings, enroll_paths\n",
    "testX, testy = test_embeddings, test_paths\n",
    "trainy = [label_func(Path(p)) for p in trainy]\n",
    "testy = [label_func(Path(p)) for p in testy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df69853",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(trainX)\n",
    "testX = in_encoder.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956dd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a760bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, trainX, trainy, testX, testy):\n",
    "    # predict\n",
    "    yhat_train = model.predict(trainX)\n",
    "    yhat_test = model.predict(testX)\n",
    "    # score\n",
    "    score_train = accuracy_score(trainy, yhat_train)\n",
    "    score_test = accuracy_score(testy, yhat_test)\n",
    "    # summarize\n",
    "    print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5541597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "evaluate(model, trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest neighbors\n",
    "# model = KNeighborsClassifier(n_neighbors=5)\n",
    "# model.fit(trainX, trainy)\n",
    "# evaluate(model, trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2bb2e",
   "metadata": {},
   "source": [
    "## Unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a762c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_paths = get_image_files(\"dogs/recognition/unknown/enroll\")\n",
    "unknown_embeddings = calculate_embeddings_for_dataset(learn, unknown_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ee99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknownX, unknowny = unknown_embeddings, unknown_paths\n",
    "unknowny = [Path(p).parent.name for p in unknowny]\n",
    "\n",
    "unknownX = in_encoder.transform(unknownX)\n",
    "# fakey = np.ones(len(unknownX)) * testy.max() + 100 # make up fake class index\n",
    "# evaluate(model, trainX, trainy, unknownX, fakey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_unknown = model.predict_proba(unknownX)\n",
    "max_prob = prob_unknown.max(axis=1)\n",
    "correct_unknown = len(unknowny) - len(max_prob[max_prob > 0.6])\n",
    "print(f\"unknown correct: {correct_unknown} / {len(unknowny)} ( {100*correct_unknown/len(unknowny)} %) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME this is actually testing the number of test items whose max prob is higher than a threshold\n",
    "# we're not seeing if it's actually correct\n",
    "prob_test = model.predict_proba(testX)\n",
    "max_prob_test = prob_test.max(axis=1)\n",
    "correct_test = len(max_prob_test[max_prob_test > 0.6])\n",
    "print(f\"test correct: {correct_test} / {len(testy)} ( {100*correct_test/len(testy)} %) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99be22",
   "metadata": {},
   "source": [
    "## Approximate nearest neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043099d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = enroll_embeddings.shape[1]\n",
    "metric = \"cosine\"\n",
    "if metric == \"euclidean\":\n",
    "    index = faiss.IndexFlatL2(dimensions)\n",
    "elif metric == \"cosine\":\n",
    "    index = faiss.IndexFlatIP(dimensions)\n",
    "    faiss.normalize_L2(embeddings)\n",
    "index = faiss.IndexIDMap(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661403f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.add(enroll_embeddings)\n",
    "enroll_ids = np.array([i for i,e in enumerate(enroll_embeddings)])\n",
    "index.add_with_ids(enroll_embeddings, enroll_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090939fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_show(index, i, test_paths, test_embeddings, k=5):\n",
    "    q = np.expand_dims(test_embeddings[i], axis=0)\n",
    "    distances, neighbors = index.search(q, k)\n",
    "    print(distances)\n",
    "    print(neighbors)\n",
    "    print(f\"query class: {test_paths[i].parent.name}\")\n",
    "    img = PILImage.create(test_paths[i])\n",
    "    show_image(img)\n",
    "    for p in enroll_paths[neighbors[0]]:\n",
    "        print(p)\n",
    "        img = PILImage.create(p)\n",
    "        show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(index, embedding, k=5):\n",
    "    q = np.expand_dims(embedding, axis=0)\n",
    "    distances, neighbors = index.search(q, k)\n",
    "#     query_class = test_paths[i].parent.name\n",
    "    pred_paths = enroll_paths[neighbors[0]]\n",
    "    pred_classes = [p.parent.name for p in pred_paths]\n",
    "    max_class = max(set(pred_classes), key=pred_classes.count)\n",
    "    count_max_class = pred_classes.count(max_class)\n",
    "    if count_max_class > k // 2:\n",
    "        # we have a winner\n",
    "        return count_max_class\n",
    "    else:\n",
    "        # not confident enough\n",
    "        return -1\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a174af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_eval(index, i, test_paths, test_embeddings, k=5):\n",
    "    q = np.expand_dims(test_embeddings[i], axis=0)\n",
    "    distances, neighbors = index.search(q, k)\n",
    "    query_class = test_paths[i].parent.name\n",
    "    pred_paths = enroll_paths[neighbors[0]]\n",
    "#     print(pred_paths)\n",
    "    pred_classes = [p.parent.name for p in pred_paths]\n",
    "    max_class = max(set(pred_classes), key=pred_classes.count)\n",
    "    count_max_class = pred_classes.count(max_class)\n",
    "    if count_max_class > k // 2:\n",
    "        # we have a winner\n",
    "        acc = 1.0 if query_class == max_class else 0.0\n",
    "    else:\n",
    "        # not confident enough\n",
    "        acc = 0.0\n",
    "#     print(f\"max_class: {max_class}  {foo}\")\n",
    "#     print(pred_classes)\n",
    "#     acc = 1.0 if query_class == pred_class else 0.0\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715256ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.0\n",
    "n = len(test_paths)\n",
    "for i in range(len(test_paths[:n])):\n",
    "    acc += query_eval(index, i, test_paths, test_embeddings)\n",
    "acc /= n\n",
    "print(f\"final acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e18fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = 0.0\n",
    "# n = len(test_paths)\n",
    "# for i in range(len(test_paths[:n])):\n",
    "#     query_class_str = query_class = test_paths[i].parent.name\n",
    "#     pred_class_int = search(index, test_embeddings[i])\n",
    "#     NOT_FINISHED__MUST_CONVERT_CLASS_ID_TO_CLASS_STRING\n",
    "# acc /= n\n",
    "# print(f\"final acc: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog",
   "language": "python",
   "name": "dog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
