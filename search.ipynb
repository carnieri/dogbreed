{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from enroll import FaissImageSearch\n",
    "from utils import label_func, get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a1729",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(\"dogs/train/exported_resnext50_32x4d.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searcher = NaiveImageSearch(learn)\n",
    "searcher = FaissImageSearch(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_paths = get_image_files(\"dogs/recognition/enroll/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96793054",
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_class_names = [label_func(p) for p in enroll_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_imgs = [PILImage.create(p) for p in enroll_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c67a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "searcher.enroll_many(enroll_imgs, enroll_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = get_image_files(\"dogs/recognition/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_names = [label_func(p) for p in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = [PILImage.create(p) for p in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_embeddings = get_embedding(searcher.learn, searcher.embedder, test_imgs)\n",
    "# pickle.dump(test_embeddings, open(\"test_embeddings.pickle\", \"wb\"))\n",
    "test_embeddings = pickle.load(open(\"test_embeddings.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d148bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faiss(searcher, path, k=3):\n",
    "    img = PILImage.create(path)\n",
    "    ds, ixs, names, winner = searcher.search(img, k=k)\n",
    "    return ds, ixs, names, winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8862f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_faiss(searcher, test_paths[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e184f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(searcher, path, k=3):\n",
    "    img = PILImage.create(path)\n",
    "    ds, ixs, names, winner = searcher.search(img, k=k)\n",
    "    print(list(zip(ds, ixs, names)))\n",
    "    print(f\"query: {label_func(path)}\")\n",
    "    show_image(PILImage.create(path))\n",
    "    for i in range(k):\n",
    "        print(f\"result: {names[i]}\")\n",
    "        show_image(searcher.imgs[ixs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure accuracy on test set for k=1 nearest neighbor\n",
    "def search_accuracy(imgs, embeddings, class_names):\n",
    "    distances_correct = []\n",
    "    distances_incorrect = []\n",
    "    distances_empty = []\n",
    "    distances_all = []\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    empty = 0\n",
    "    for i in range(len(imgs)):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        ds, ixs, names, winner = searcher.search_from_vector(np.expand_dims(embeddings[i], axis=0), k=5)\n",
    "        if winner is not None:\n",
    "            if winner == class_names[i] and ds[0] >= 0.78:\n",
    "                correct += 1\n",
    "                distances_correct.append(ds[0])\n",
    "            else:\n",
    "                incorrect += 1\n",
    "                distances_incorrect.append(ds[0])\n",
    "        else:\n",
    "            distances_empty.append(ds[0])\n",
    "        distances_all.append(ds[0])\n",
    "    acc = float(correct) / len(imgs)\n",
    "    print(f\"acc: {acc}\")\n",
    "    distances_all = np.array(distances_all)\n",
    "    distances_correct = np.array(distances_correct)\n",
    "    distances_incorrect = np.array(distances_incorrect)\n",
    "    distances_empty = np.array(distances_empty)\n",
    "    return acc, distances_all, distances_correct, distances_incorrect, distances_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, distances_all, distances_correct, distances_incorrect, distances_empty = search_accuracy(test_imgs, test_embeddings, test_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6aa97",
   "metadata": {},
   "source": [
    "## Plot distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf66b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(imgs, embeddings, class_names):\n",
    "    acc, distances_all, distances_correct, distances_incorrect, distances_empty = search_accuracy(imgs, embeddings, class_names)\n",
    "    print(f\"distances_all.shape: {distances_all.shape}\")\n",
    "    print(f\"distances_correct.shape: {distances_correct.shape}\")\n",
    "    print(f\"distances_incorrect.shape: {distances_incorrect.shape}\")\n",
    "    print(f\"distances_empty.shape: {distances_empty.shape}\")\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(distances_all)\n",
    "    plt.axis([0, len(distances_all), 0, 1.0])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(distances_correct)\n",
    "    plt.axis([0, len(distances_correct), 0, 1.0])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(distances_incorrect)\n",
    "    plt.axis([0, len(distances_incorrect), 0, 1.0])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(distances_empty)\n",
    "    plt.axis([0, len(distances_empty), 0, 1.0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7325e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(test_imgs, test_embeddings, test_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed846e78",
   "metadata": {},
   "source": [
    "## Search for unknown breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_paths = get_image_files(\"dogs/recognition/unknown/test\")\n",
    "unknown_class_names = [label_func(p) for p in unknown_paths]\n",
    "unknown_imgs = [PILImage.create(p) for p in unknown_paths]\n",
    "# unknown_embeddings = get_embedding(searcher.learn, searcher.embedder, unknown_imgs)\n",
    "# pickle.dump(unknown_embeddings, open(\"unknown_embeddings.pickle\", \"wb\"))\n",
    "unknown_embeddings = pickle.load(open(\"unknown_embeddings.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(unknown_imgs, unknown_embeddings, unknown_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87643b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_faiss(searcher, unknown_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967eea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rejection_accuracy(imgs, embeddings, class_names, threshold=0.78):\n",
    "    \"\"\"Assumes that samples are from classes unknown to the database.\"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(imgs)):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        ds, ixs, names, winner = searcher.search_from_vector(np.expand_dims(embeddings[i], axis=0), k=1)\n",
    "        if ds[0] < threshold:\n",
    "            correct += 1\n",
    "    acc = float(correct) / len(imgs)\n",
    "    print(f\"acc: {acc}\")\n",
    "    return acc\n",
    "#     prob_unknown = model.predict_proba(unknownX)\n",
    "#     max_prob = prob_unknown.max(axis=1)\n",
    "#     correct_unknown = len(unknowny) - len(max_prob[max_prob > 0.6])\n",
    "#     print(f\"unknown correct: {correct_unknown} / {len(unknowny)} ( {100*correct_unknown/len(unknowny)} %) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ab6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rejection_accuracy(unknown_imgs, unknown_embeddings, unknown_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf104874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog",
   "language": "python",
   "name": "dog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
